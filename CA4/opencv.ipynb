{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "# Load a color image in grayscale\n",
    "img = cv2.imread('OpenCV_Logo.png',1)\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following program loads OpenCV logo image and saves its greyscale version when ‘s’ key\n",
    "is pressed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "# Load an color image in grayscale\n",
    "img = cv2.imread('OpenCV_Logo.png',0)\n",
    "cv2.imshow('image',img)\n",
    "key=cv2.waitKey(0)\n",
    "if key==ord('s'):\n",
    "    cv2.imwrite(\"opencv_logo_GS.png\", img)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " img = cv.imread(\"OpenCV_Logo.png\", 1)\n",
    ">>> b,g,r = cv.split(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[:, :, 0]=0\n",
    ">>> cv.imshow(\"image\", img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Bitwise Operation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate the use of these operators, two images with filled and empty circles are\n",
    "taken.\n",
    "Following program demonstrates the use of bitwise operators in OpenCV-Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img1 = cv2.imread('a.png')\n",
    "img2 = cv2.imread('b.png')\n",
    "dest1 = cv2.bitwise_and(img2, img1, mask = None)\n",
    "dest2 = cv2.bitwise_or(img2, img1, mask = None)\n",
    "dest3 = cv2.bitwise_xor(img1, img2, mask = None)\n",
    "cv2.imshow('A', img1)\n",
    "cv2.imshow('B', img2)\n",
    "cv2.imshow('AND', dest1)\n",
    "cv2.imshow('OR', dest2)\n",
    "cv2.imshow('XOR', dest3)\n",
    "cv2.imshow('NOT A', cv2.bitwise_not(img1))\n",
    "cv2.imshow('NOT B', cv2.bitwise_not(img2))\n",
    "if cv2.waitKey(0) & 0xff == 27:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In another example involving bitwise operations, the opencv logo is superimposed on\n",
    "another image. Here, we obtain a mask array calling threshold() function on the logo\n",
    "and perform AND operation between them.\n",
    "Similarly, by NOT operation, we get an inverse mask. Also, we get AND with the\n",
    "background image.\n",
    "Following is the program which determines the use of bitwise operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "img1 = cv.imread('lena.jpg')\n",
    "img2 = cv.imread('whitelogo.png')\n",
    "rows,cols,channels = img2.shape\n",
    "roi = img1[0:rows, 0:cols]\n",
    "img2gray = cv.cvtColor(img2,cv.COLOR_BGR2GRAY)\n",
    "ret, mask = cv.threshold(img2gray, 10, 255, cv.THRESH_BINARY)\n",
    "mask_inv = cv.bitwise_not(mask)\n",
    "# Now black-out the area of logo\n",
    "img1_bg = cv.bitwise_and(roi,roi,mask = mask_inv)\n",
    "# Take only region of logo from logo image.\n",
    "img2_fg = cv.bitwise_and(img2,img2,mask = mask)\n",
    "# Put logo in ROI\n",
    "dst = cv.add(img2_fg, img1_bg)\n",
    "img1[0:rows, 0:cols ] = dst\n",
    "cv.imshow(Result,img1)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Draw Shapes and Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapes\n",
    "import numpy as np\n",
    "import cv2\n",
    "img = cv2.imread('LENA.JPG',1)\n",
    "cv2.line(img,(20,400),(400,20),(255,255,255),3)\n",
    "cv2.rectangle(img,(200,100),(400,400),(0,255,0),5)\n",
    "cv2.circle(img,(80,80), 55, (255,255,0), -1)\n",
    "cv2.ellipse(img, (300,425), (80, 20), 5, 0, 360, (0,0,255), -1)\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following program adds a text caption to a photograph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text\n",
    "import numpy as np\n",
    "import cv2\n",
    "img = cv2.imread('messi.JPG',1)\n",
    "txt=\"Lionel Messi\"\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.putText(img,txt,(10,100), font, 2,(255,255,255),2,cv2.LINE_AA)\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mouse Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to Circle mode\n",
      "Switched to Rectangle mode\n",
      "Switched to Circle mode\n",
      "Switched to Rectangle mode\n",
      "Switched to Circle mode\n",
      "Switched to Rectangle mode\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "drawing = False\n",
    "mode = True\n",
    "ix, iy = -1, -1\n",
    "rectangles = []\n",
    "circles = []\n",
    "\n",
    "def mouse_event_handler(event, x, y, flags, param):\n",
    "    global ix, iy, drawing, mode, rectangles, circles\n",
    "\n",
    "    # Left mouse button down - start drawing\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        ix, iy = x, y\n",
    "\n",
    "    # Mouse move - update the shape being drawn\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing:\n",
    "            img_copy = img.copy()\n",
    "            if mode:  # Drawing rectangle\n",
    "                cv2.rectangle(img_copy, (ix, iy), (x, y), (0, 255, 0), 2)\n",
    "            else:  # Drawing circle\n",
    "                radius = int(np.sqrt((x - ix) ** 2 + (y - iy) ** 2))\n",
    "                cv2.circle(img_copy, (ix, iy), radius, (0, 0, 255), 2)\n",
    "            cv2.imshow(\"Mouse Event Window\", img_copy)\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        if mode:\n",
    "            rectangles.append((ix, iy, x, y))\n",
    "            cv2.rectangle(img, (ix, iy), (x, y), (0, 255, 0), 2)\n",
    "        else:\n",
    "            radius = int(np.sqrt((x - ix) ** 2 + (y - iy) ** 2))\n",
    "            circles.append((ix, iy, radius))\n",
    "            cv2.circle(img, (ix, iy), radius, (0, 0, 255), 2)\n",
    "        cv2.imshow(\"Mouse Event Window\", img)\n",
    "\n",
    "    elif event == cv2.EVENT_RBUTTONDOWN:\n",
    "        mode = not mode\n",
    "        shape = \"Rectangle\" if mode else \"Circle\"\n",
    "        print(f\"Switched to {shape} mode\")\n",
    "\n",
    "img = np.ones((512, 512, 3), dtype=np.uint8) * 255\n",
    "\n",
    "cv2.namedWindow(\"Mouse Event Window\")\n",
    "cv2.setMouseCallback(\"Mouse Event Window\", mouse_event_handler)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow(\"Mouse Event Window\", img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "img = cv2.imread('messi.JPG',1)\n",
    "height, width = img.shape[:2]\n",
    "res = cv2.resize(img,(int(width/2), int(height/2)), interpolation =\n",
    "cv2.INTER_AREA)\n",
    "cv2.imshow('image',res)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotate Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "img = cv2.imread('OpenCV_Logo.png',1)\n",
    "h, w = img.shape[:2]\n",
    "center = (w / 2, h / 2)\n",
    "mat = cv2.getRotationMatrix2D(center, 90, 1)\n",
    "rotimg = cv2.warpAffine(img, mat, (h, w))\n",
    "cv2.imshow('original',img)\n",
    "cv2.imshow('rotated', rotimg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv.imread('gradient.png',0)\n",
    "ret,img1 = cv.threshold(img,127,255,cv.THRESH_BINARY)\n",
    "plt.subplot(2,3,1),plt.imshow(img,'gray',vmin=0,vmax=255)\n",
    "plt.title('Original')\n",
    "plt.subplot(2,3,2),plt.imshow(img1,'gray',vmin=0,vmax=255)\n",
    "plt.title('Binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv.imread('messi.jpg',0)\n",
    "img = cv.medianBlur(img,5)\n",
    "th1 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "cv.THRESH_BINARY,11,2)\n",
    "th2 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "cv.THRESH_BINARY,11,2)\n",
    "titles = ['Original', 'Mean Thresholding', 'Gaussian Thresholding']\n",
    "images = [img, th1, th2]\n",
    "for i in range(3):\n",
    "    plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv.imread('opencv_logo_gs.png')\n",
    "kernel = np.ones((3,3),np.float32)/9\n",
    "dst = cv.filter2D(img,-1,kernel)\n",
    "plt.subplot(121),plt.imshow(img),plt.title('Original')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(dst),plt.title('Convolved')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv.imread('lena.jpg', 0)\n",
    "edges = cv.Canny(img,100,200)\n",
    "plt.subplot(121),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(edges,cmap = 'gray')\n",
    "plt.title('Edges of original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv.imread('lena.jpg')\n",
    "color = ('b','g','r')\n",
    "for i,col in enumerate(color):\n",
    "    hist = cv.calcHist([img],[i],None,[256],[0,256])\n",
    "plt.plot(hist, color = col)\n",
    "plt.xlim([0,256])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread('messi.jpg')\n",
    "img1 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY )\n",
    "img2 = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "# Displaying the image\n",
    "cv2.imshow('original', img)\n",
    "cv2.imshow('Gray', img1)\n",
    "cv2.imshow('HSV', img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphological Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "img = cv.imread('LinuxLogo.jpg',0)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "erosion = cv.erode(img,kernel,iterations = 1)\n",
    "dilation = cv.dilate(img,kernel,iterations = 1)\n",
    "cv.imshow('Original', img)\n",
    "cv.imshow('Erosion', erosion)\n",
    "cv.imshow('Dialation', dilation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Contours\n",
    "\n",
    "Following code is an example of drawing contours on an input image having three shapes\n",
    "filled with black colours.\n",
    "In the first step, we obtain a gray image and then perform the canny edge detection.\n",
    "On the resultant image, we then call findContours() function. Its result is a point vector.\n",
    "We then call the drawContours() function.\n",
    "The complete code is as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('shapes.png')\n",
    "cv2.imshow('Original', img)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "canny = cv2.Canny(gray, 30, 200)\n",
    "contours, hierarchy = cv2.findContours(canny,\n",
    "cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "print(\"Number of Contours = \" ,len(contours))\n",
    "cv2.imshow('Canny Edges', canny)\n",
    "cv2.drawContours(img, contours, -1, (0, 255, 0), 3)\n",
    "cv2.imshow('Contours', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template Matching\n",
    "\n",
    "In an example below, an image having Indian cricketer Virat Kohli’s face is used as a\n",
    "template to be matched with another image which depicts his photograph with another\n",
    "Indian cricketer M.S.Dhoni.\n",
    "Following program uses a threshold value of 80% and draws a rectangle around the\n",
    "matching face:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('Dhoni-and-Virat.jpg',1)\n",
    "cv2.imshow('Original',img)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "template = cv2.imread('virat.jpg',0)\n",
    "cv2.imshow('Template',template)\n",
    "19. OpenCV-Python — Template MatchingOpenCV-Python\n",
    "51\n",
    "w,h = template.shape[0], template.shape[1]\n",
    "matched = cv2.matchTemplate(gray,template,cv2.TM_CCOEFF_NORMED)\n",
    "threshold = 0.8\n",
    "loc = np.where( matched >= threshold)\n",
    "for pt in zip(*loc[::-1]):\n",
    "cv2.rectangle(img, pt, (pt[0] + w, pt[1] + h), (0,255,255), 2)\n",
    "cv2.imshow('Matched with Template',img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Addition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kalam = cv2.imread('kalam.jpg')\n",
    "einst = cv2.imread('einstein.jpg')\n",
    "img = cv2.add(kalam, einst)\n",
    "cv2.imshow('addition', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv.imread('lena.jpg',0)\n",
    "dft = cv.dft(np.float32(img),flags = cv.DFT_COMPLEX_OUTPUT)\n",
    "dft_shift = np.fft.fftshift(dft)\n",
    "magnitude_spectrum = 20*np.log(cv.magnitude(dft_shift[:,:,0],dft_shift[:,:,1]))\n",
    "plt.subplot(121),plt.imshow(img, cmap = 'gray')\n",
    "plt.title('Input Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(magnitude_spectrum, cmap = 'gray')\n",
    "plt.title('Magnitude Spectrum'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capture Video From Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "cam = cv.VideoCapture(0)\n",
    "cc = cv.VideoWriter_fourcc(*'XVID')\n",
    "file = cv.VideoWriter('output.avi', cc, 15.0, (640, 480))\n",
    "if not cam.isOpened():\n",
    "print(\"error opening camera\")\n",
    "exit()\n",
    "while True:\n",
    "# Capture frame-by-frame\n",
    "ret, frame = cam.read()\n",
    "# if frame is read correctly ret is True\n",
    "if not ret:\n",
    "print(\"error in retrieving frame\")\n",
    "break\n",
    "img = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "cv.imshow('frame', img)\n",
    "file.write(img)\n",
    "if cv.waitKey(1) == ord('q'):\n",
    "break\n",
    "cam.release()\n",
    "file.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Image from Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "cam = cv2.VideoCapture(\"video.avi\")\n",
    "frameno = 0\n",
    "while(True):\n",
    "ret,frame = cam.read()\n",
    "if ret:\n",
    "# if video is still left continue creating images\n",
    "name = str(frameno) + '.jpg'\n",
    "print ('new frame captured...' + name)\n",
    "cv2.imwrite(name, frame)\n",
    "frameno += 1\n",
    "else:\n",
    "break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "img = cv2.imread('Dhoni-and-virat.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "roi_gray = gray[y:y+h, x:x+w]\n",
    "roi_color = img[y:y+h, x:x+w]\n",
    "eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "for (ex,ey,ew,eh) in eyes:\n",
    "cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "img = cv.imread('home.jpg')\n",
    "gray= cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "sift = cv.SIFT_create()\n",
    "kp = sift.detect(gray,None)\n",
    "img=cv.drawKeypoints(gray,kp,img)\n",
    "cv.imwrite('keypoints.jpg',img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "img1 = cv2.imread('lena.jpg')\n",
    "img2 = cv2.imread('lena-test.jpg')\n",
    "# Convert it to grayscale\n",
    "img1_bw = cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "img2_bw = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "orb = cv2.ORB_create()\n",
    "queryKeypoints, queryDescriptors = orb.detectAndCompute(img1_bw,None)\n",
    "trainKeypoints, trainDescriptors = orb.detectAndCompute(img2_bw,None)\n",
    "matcher = cv2.BFMatcher()\n",
    "matches = matcher.match(queryDescriptors,trainDescriptors)\n",
    "img = cv2.drawMatches(img1, queryKeypoints,\n",
    "img2, trainKeypoints, matches[:20],None)\n",
    "img = cv2.resize(img, (1000,650))\n",
    "cv2.imshow(\"Feature Match\", img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
